 Technology, but first of all as usual, we have any question about the first part, something that is not clear, something that you want to ask? Or was everything OK? I don't know. Put that there. No question? So if there are no other questions, we can continue. Just briefly recap what we have said. We say that there is an interplay between law and technology. And the relationship between law and technology is the mutual concept. It means that the law can be used in order to shape technology. But we can also use technology in order to implement some law provisions, some required behavior that through the technology can be stronger in terms of constraints, in terms of the push to be in line with what is required by the law. This was the bi-design approach. The idea is to create a design system that intrinsically limits some possibility as regards the use of the device that is not aligned with the legal requirement. And this is the so-called bi-design approach that is used. And we have discussed about the opportunities and the limitations of this kind of application for law. Different friends and that's the fact that technology has been done some trick in the years according to the fact that the post had the high level of the law and the main cycle of the IP and the proff. And finally, we talked about the different kind of approach in terms of our laws of law. Shaping technology, of course, is not necessary. Starting point is not necessary. The law made by the state, but you can have a lot of process based on separation, based on cause of conduct that are quite useful and relevant, mainly in the field of data protection. So this was more or less what we discussed and when we discussed about risk as one of the key elements that the technology regulation have to address. Because new technology increased the number of risks that are created in society. So we have to face this kind of risk through two main instruments, the mitigation measure, through the risk assessment, the risk management. And in the case in which the risk is not possible to measure and properly assess, the adoption of sort of preventing approach, precautionary approach, it means that you stop to put on the market, make a vulnerable use of some specific product application to the fact that the risk is not still manageable, we can say. It doesn't mean that we stop the research innovation in the field, but simply the product development in terms of something that can be used in a real world by consumers or user in general. We can have some trials in control environment, or we can continue the research team and countless. So this is just to recap briefly the last point that we outlined during the last classes. And now the point that I want to raise, the fact that when we discuss about the regulation, we discuss mainly, of course, our focus will be on the EU level, on the EU perspective. But there is not only the EU perspective. Also during the discussion, we see that there is a lot of interplay between the EU context, we can say, and other areas, mainly the US, because there is quite sometimes difficult dialogue between EU and US with regard to transfer and data protection. But also other areas in which there is an increasing attention for the use of data, sometimes also based on certain ideas of sovereignty. For instance, in Russia, in China, in other countries, they want to have digital sovereignty with an interpretation of this notion that it's very close to state control over information and over electronic means of communication. So in this context, it's very important to have a mindset that we can do the interaction between our model and other model that exists in other countries. Of course, we have no opportunity to discuss all these issues of concerning the comparative approach to data protection. But we can outline some key points. And in applying these key points, we have to start in front of the idea that when we talk about data, when we talk about technology in general, as we already said, it's not only that technology that exists per se, but technology is part of society. So the societal dimension is overlapping and connected with the technology dimension. And in this regard, there are three elements that should be considered. The first one is the transnational nature of the relationship. The second one is the transcultural aspect of this relationship. And the third one is the ongoing regulatory competition in the field of digital law. So if we look at the transnational dimension of the relationship concerning the application of technology and mainly digital technology, we can consider that, for instance, if you look at products, digital product, compared to many other products, are easier to be shared and distributed all over the world. And of course, distributing a product all over the world, it means that this rise problem of conformity with the national regulation. As we say, the national regulation of third base, so it means that in some countries, some products could be commercialized only on the certain specific requirement. So this transnational dimension is something that we have to take into account when we talk about the product, when we talk about also protective products such as copyrighted materials, et cetera, because of course there is a problem concerning, on one hand, the conformity to the local standard, and on the other hand, the increasing risk that in other countries, some provision that regulate and protect the materials, the product that you realize, can be infringed. And this is the case in instance, so the copyright has been for a long time the case of the copyright. So what this means, it means that the first issue relates to the fact that when you want to put on the market in another country, some product, you should take into account some restriction that might exist. For instance, there was an important case years ago that was the eBay case in which the true eBay was made available some materials about the Nazi and fascist period. And these materials were made available in France. And in France, there is a criminal law that forbid any kind of commercialization of Nazi and fascist materials. Unfortunately, we have not the same in Italy. But in France exists, and so there was the problem that these materials made available online through eBay were of course available also in the French territory. And this is what we said last time on the difficulties in combining global network like internet and the traditional territory-based approach of the state regulation. So before internet was no any issues because if we have a shop and you put it in the shop and Nazi symbols or materials, of course, the police can check and remove them and give you a sanction. But online is much more difficult because if you put something on eBay, this is available in France, in Germany, whatever you want, including countries in which this is illegal. So this rise problem of the transnational dimension of the internet. Of course, now, considering the limitation of this course, we cannot dig in all the issues and the way which we can solve or address this kind of problem. But just to point out that when you make something and made available online, you have to consider that is a value in different jurisdiction. And in some jurisdiction, that activity of that product can be not allowed by the law. And this can take problems for your business and for the delta on your product or for the standing on your product. On the opposite side, copyright infringement case is interesting because here we have a situation in which we have almost a general protection because we're going to copyright at the right international agreement at a very high level. So almost all the judicial recognize copyright and there is a sort of international monetization about the copyright regulation. So here we have not a problem of a lot of differences among countries. But yes, we have a problem of the enforcement of this provision. What it means? It means that if you have a copyright product that is made available, for instance, on your website or whatever you want, the same product can be downloaded is the case of scientific paper, for instance, can be legitimately downloaded by a user in your country. But then reuse in another platform, legal platform, make it available for free in other countries, for instance. I remember years ago, I was invited to China by the Chinese University and we had a nice Christian meeting with the Chinese business man that this brilliant idea to grab and download all the scientific paper and make them available in its own platform in China for the Chinese audience, we can say. And he didn't realize that it was not possible. He said, why not? I downloaded and made it available. Okay, but there's a copyright protection, you know, we have to ask for and make an agreement. So just to point out that is not so generally a fact that this idea that exists protect materials. So it might be the case, and it is the case that there are platforms that are on our website that they redistribute protective materials without any authorization, without analyzing. So of course, in this case, there's a problem of infringement, there's a clear infringement of the copyright law, but what is the problem here related to the transnational dimension? The problem here is the enforcement, because of course, there is a problem that is clear that there's infringement, but how to enforce in a country that is far from your country, you have to make a legal action in that country, so it's expensive in that of course. You have to find in that country that can be not so strong with anti-rotational purpose on this kind of issues. And at the end of the day, you also have to find company or a natural person that is able to pay for the damage that they create. And sometimes you find a very small company that have no money, so you have to, of course, you can stop the illicit behavior that is fine, but you cannot have a compensation for the damages. Of course, there are strong systems for criminal infringement, for instance, for the child abuse or child pornography, et cetera. It's possible through the legal provision, according to Italy, but also in other countries, through the criminal provision, you can stop at high level, at level of national system of the assembly. You cannot have access to the WIP that are selected because they distribute child pornography or other illicit companies. This is a strong instrument because it is a block at level of network, so you cannot have access, but of course, if it's good in terms of reducing the distribution of the material, also in this case, we meant the problem of the legal enforcement. So if you want to punish these people, if you want to reach them and put them in jail, of course, again, we have a problem of the transnational dimension, so you need a legal order that should be enforced in that country and you have to arrest them, make a trial in that country, or ask for a trial in your country, according to international cooperation on the judiciary sector. So again, it's quite difficult. And this is a continuous struggle that is related to the fact that we have two dimensions, the national dimension and international dimension of the network. And unfortunately, the online network are more pervasive and more immaterial, we can say, than other networks, because we have also, for instance, global network for flights or for goods or for supply chain, but they are much more concrete, we can say, and it's easier to stop, to some extent, the flows or to regulate the flows. In internet, this is much more difficult. There are many solutions that permit to circumvent the gate. If you want to stop some flights, you can stop some flights coming from some countries because you act on the airport, they cannot land in the airport. But in internet, you cannot stop landing content in your country, it's much more difficult. So this is the first aspect that we all have to take into account when we discuss about privacy or about the digital content, et cetera, that we could have the best law in our country or in Europe, but that is the problem. What happens outside? How we can protect outside? For this reason, in the GDPR, in the proposal of AI Act, in the digital service act, in many recent provision of the European Union, there is a focus on this extra territorial effect, we can say, and it's more and more required by the EU to have the power to extend the application of the law, also outside the European Union border, when there is an activity that might affect the EU citizen or the people that live in Europe. It's something that we will see when we discuss about the scope of the GDPR. The GDPR is applicable not only to the company or to the person that are based in Europe, but also when foreign company based in another country process personal data affecting people that are in Europe. And this, of course, is an extra territorial application of an EU law. This kind of extra territorial application, again, represents a derogation to the territory-based approach of the state law, and of course, to create at international level some, we can say, reaction or conflicts with other countries, because it means that you entitle your entity, in this case, the European Union, to extend its power to something that is done in another country, to the fact that that activity may affect your city and other people living in Europe. Of course, this extension of power, the activities done in another country, in which, for instance, these activities are admitted or not regulated, creates a certain clash between the traditional idea of state territory competence. It's accepted in some countries, accepted with regard for data protection, for instance, because of course, then there are geopolitical reasons, the European Union market, and the fact that there was also sort of, we can say a sort of, percentage-wave approach, the EU was able to convince many countries to adopt the similar rules as regard data protection, the so-called brass of effect, that maybe we mentioned in the next classes. So for a serious reason, for the moment in the field of data protection, this extra territory of approach of the European Union does not create a lot of reaction on a few countries. But of course, you cannot imagine that we can always have this approach, and on the other hand, there are also other countries that say, oh, but we can do the same. And we can ask the European provider to be compliant to the law in our countries, although they are based in Europe. And of course, when this is required by countries that are not so democratically oriented, there's a lot of problem and concern. So this is a topic that I want to just outline, because we're only discussing the GDPF, we have no time to dig too much on that, but is behind the entire discussion. On the background, we have this big problem of the crowd-national dimension. Another big problem that we have not necessarily in data protection, but for instance, in content moderation, or in the discussion about ethics, is the transcultural dimension. Transcultural dimension means that there are not only different territories in terms of regulation, but there are also different cultures. And the cultural dimension is more and more relevant when we imagine to create our own life using the suggestion by a famous philosopher. Our life, it means mixing the online and offline life. In this experience that connected this two dimension, of course, your activity transposing the online environment can, this activity represent your culture, your view or your attitude with regard to society and the world. But what is the problem? The problem that in different cultures, the same behavior can be classified in a different way. If you go to Asia, for instance, in some country, in the travel guide, there is a specific note for Europeans that say that some behavior that in Europe are considered as common, in that country are considered as offensive or not accepted, we can say. And it is the same if you read the guidelines for the people coming to Europe. So there are differences in cultures. So imagine to transpose the difference in the content moderation. When you have to decide to take down a video, for instance, in a platform like YouTube, of course, what is the difference between joking or being defamatory? Something that in Italy can be considered as joking in another country can be considered very offensive according to the specific culture of that area. So you can imagine how much is difficult for the platform to mind these kind of issues because there are several options. The first option is to transpose in the global platform the mindset of the platform owners. And it's something that we have seen with Facebook. You remember that famous, decided to take down some paintings or some photos of women breast because it was considered as a game day time and condition. How we can classify this attitude? It's a very conservative US approach about sex and which they are concerned. By the way, US society is not so concerned. But they are concerned about the fact that showing the breast of a woman is considered as a problem. And why if you look to the, all the ancient Greek or Roman statutes and arts and also post-fac, in the following centuries there are a lot of the entity and nobody is concerned. And for the reason they also take down some paintings without any discrimination because the AI is not able to discriminate between a photo and a painting sometimes. And so, sometimes, at that time. And so the problem is that this reflect an approach that is the approach of the platform owner. That through time and condition, for this reason we mentioned the relevance of the contract in shaping the sphere, through time and condition, decide what is accepted or not. But according to its own culture, if you come from Italy, you can be considered family, some provision, some limitation. Or if you come from another country, you can be considered too low, we can say, the level of prohibition. Because another country is not an approval of breast, but also other parts of the body should not be publicly shown. So this approval of trans-cultural dimension that can be addressed through a top-down regulation, created this kind of issues. Or can be addressed in a more difficult way to a contextual-based approach. And this is what is now is doing by some of the big platform. So created things with the local expertise, with a variety in terms of culture, that can say, oh, this is in Italy, it's joking, but in India, this is not joking. And this is the format. The same situation classified different, based on the expertise of local expert that they're able to provide the correct contextualization, we can say, of the message we provide the content that they see. And this just mentioned, but as you are a bit of scientist, this also show another hidden part that I know if you discuss in other courses, but it's also related to the topic of data editor, which do not need to mention that. The other issue is about the development of AI. That AI is not done only through algorithms and through computer scientists, as you know, but there are a lot of people, thousands of people that work behind the scene, supporting this smart AI. The magnet is not so smart. So labeling tests, labeling images, removing content, that's it. So, large part of the AI performance is not based necessarily on the quality algorithm, but it's based on thousands of people that make this sort of debugging activity. Many of them, labels, images, many of them take down context. All these activity that is generally called mechanical turkey activities is something that we don't know, but rise a lot of concern also in terms of radical approach because we talk about people in some low income country that are asked to stay eight hours in front of shocking images about child pornography, violence or other kinds of content in order to support content removal, in order to train also AI to make possible a better automatization of content removal. So, this part of the human side of the artificial intelligence, and time is missing in the debate, but it's a relevant part in our increasingly also investigated by researchers at the global level. So, this is about the trans-cultural dimension that we have to consider also when we discuss and when we address the issues related to digital technologies. And the last point is about the regular competition that is related to the previous two points. So, if there are differences, if we have seen that there are global problem and different territory and regulatory approach, of course what it means, it means that this creates a sort of competition in regulating the global sphere of digital life. Because if different countries have different approaches in regulating, at local level in their territory, there's no any problem, but who will regulate at global level? What will be the standard that can be set at global level? As all the process, there is a trend in favor of a sort of uniformity, a sort of harmonization. You cannot leave having dozens of different regulations. We have to moralize, converge towards a sort of general approach. This process of harmonization is common in many, many sectors, and it's common also in the field of law. But if the certain points are different system, different rules, this means that this variety creates a regulatory competition. What it means, regulatory competition, it means that each geographical area, each state or aggregation of states, we try to put the flag and say, oh, we regulate internet, we regulate data, we regulate content moderation, in this way that is my way. Okay, this creates a problem of regulatory competition at international level in the international bodies, or also in the bilateral interaction, for instance, between EU and US. There is a clear struggle in order to decide who is the rule maker, who is able to set the rules in a sphere that is bigger than its own original territory area. And we have seen that in data, for instance, the fact that the data protection approach about in Europe is expanding around the world, of course, is very positive and make the EU, give the EU a leadership in terms of data protection regulation. But for instance, in US, we're not so happy about that, and now they try to realign their position with new specific regulation, and based on the experience, are much more reactive with AI regulation. In the AI regulation, for instance, Europe started to regulate, to discuss about the regulation of AI was the actor that made the first step in this direction, but immediately there was the reaction from the US that they are not to lose this quite light app with the data, and they present some counter proposals, some different kind of opinion, and now there is a lot of interaction between the US bodies, mainly the NIST, that is the National Institution on Standards and the Feedup Technologies, and the EU body, in order to agree on some common points. Of course, this is a limitation to the potential expensive EU approach, and there is a sort of gentleman agreement between the big player, in order to find a more compatible solution, we can say in terms of AI regulation. So, this regulatory competition is very strong, and it's very relevant, of course, not only in the digital sphere, environment, anti-trust, there are many other fields in which the leadership of one country in terms of regulation was extended to other countries that adopt a similar standard. Just to give you an example, now the large majority of the countries around the world that adopt a data protection law, adopt a data protection law that is based on the European standard. So, this is a field in which the EU framework had an impact at global level. Of course, as I mentioned, it's one of the few, many other, like anti-trust, environmental, et cetera, and the US model is stronger than the European one. Okay, so, after this introduction about the law of technology in general, the relationship between law of technology, a few words about the other key concept that you have to know. Of course, I'm aware that it's not easy to follow all these different blocks, but the life-hold introduction to our new subject, the fact that we have no experience in the field of law, is necessary to set some key notion. I have to put the lights on some aspect that concern technology, the role of law, the interaction between both, and some key idea. The territory regulation and the global regulation, and in this case, liability, because in the course, during the course, we will discuss about law and legal requirement, as we said, the peculiarity of the legal requirement or legal provision is that it can be enforced that we have to respect the law, and if you don't, there is a sanction or there is a kind of liability. So we have to spend a few words about the liability. Of course, there is a type of liability that is the criminal or administrative liability, and this is not discussed in this slide, but it's also easy to understand. A criminal liability is mainly personal liability. Usually it's not the company that is criminal liability, there are only few sections in corporate liability, but it's the individual person that is liable. So if there is a copyright infringement, for instance, and this is a violation of some kind of sanction with a criminal law, you are considered liable, and the criminal liability does many nuances according to the gravity of the action and there are different kinds of punishments, we can say, but all are based on the fact that there is a limitation of your rights. So the punishment can be paying money, limitation of your right to property, or putting someone in jail, limitation to your freedom. So the final line in the criminal process is only a limitation of individual rights. The important point that you have to keep in mind is that the criminal liability, such as the administrative liability, that is a software form of sanctioning, not based on putting the people in jail but asking to pay money, basically, and extending this obligation to pay money, not only to natural pension but also to companies, but these two forms, the criminal and administrative liability, are basically focused on the idea that they act in the public interest. They are part of public law in this regard. So what I want to say, I want to say that when someone is put in jail or has to pay money, this does not solve the problem of the damage that is or activity created. It's only the sanction that the state provides to this person or entity in order to punish the person, second to limit the propensity or the tendency of other people to replicate the same bad behavior. So the focus is the social interest not to have some kind of behavior. Put in jail that committed this infringement and give us in this way an example to the other not to follow the path we can say. But this do not solve the problem of the damage they create. So to give a very concrete example, if there is a data breach and they take a lot of information from your server and make a lot of money, having access to a bank account, whatever you want. Of course they can be put in jail, but it's not to resolve the problem that you have to a lot of damage in terms of cost that you have to cover and the people suffer damage in terms of money that they have lost. And to recover this kind of cost, you have to act through the legal action but in the civil law, in the civil arena. And this is the liability. The civil law liability, it means asking some form of a regress, of a regress and forms of protection for the interests that were infringed by some behavior. Usually asking for money if you have a damage or restoring the previous situation as far as possible. So it's important not to mix the two elements. The criminal sanction, although in terms of money, is only for the states. The money goes to the states and the money or other sanctions are just to punish the person and to give a message to the rest of the people. But this does not solve the problem of the damage suffered by the people that are the victims. And the victims, if they weren't any kind of, any form of restoring of this damage that they have suffered, they have to make a legal action. Then of course the legal action can be, is a civil law action or you can say a tort action in the common law system, but an action based, not a criminal law but based on private law we can say. So it's a private law action. In some system like in Italy, this action can be also presented in front of the criminal court, but remains a private law action because the goal is to have the payment of the damage or the restoration of the damage that we have suffered. And in this regard, with regard to liability, of course in terms of regulation of technology, there is an issue to define how we set this liability. Who is liable, how far they are liable. Because there are two extreme position if you want. On one hand you can say every time that there is a damage, the entity that created that damage is liable. Of course if you adopt this approach, it's very good for the victims because there is always someone that pay, but it is a huge burden that you put on the shoulder of those that created damage. On the other hand there is an old traditional approach based on food that also from ethics and from religion is the typical mindset. You are liable because you have done something bad and you were aware that you have done something bad because there was intention to make something bad or there was a negligence. So therefore it's based system. What is the problem? The problem is the traditional approach that is based on food does not work well in the technology context. Because when we have a product that is relied by a machine for instance, at some problem in the functioning of the machine create a product with some specific weakness that in putting a car can create an accident. Who is liable? There is no one that has a fault in that case because it was the machine. Or there are cases in which there is a human fault for instance, you make a mistake in coding some part of a program, this creates some bugs, et cetera. So we have the people, the person that is liable that is who coded that part. I know who coded that part. But if the damage you created because the software was used by bank, et cetera is of thousands or millions of euro, the single person that coded that plan is not able to pay. So it's true that the fault system has able to identify an actor that is liable but that actor is not able to pay. So in terms of effectiveness of the legal solution it is useless. For this reason in the corporate context in the industrial activities you can say we adopt sometimes standards of strict liability. Strict liability means that the company typically is liable although there is not a fault but it's liable due to the fact that has created a certain product or service that may enter some risk. So if you have a chemical company, you make business using chemical product, of course. But chemical plant can create a great problem if they don't work properly. In terms of pollution, in terms of environmental disaster and so on. And in that case you are liable regardless of the fact that there is a fault or not. You are liable because you have those that are is in the best position to control the risk that you have created and put in the society. You have a benefit from this risk, you have to pay it a negative impact. Of course what is the problem? The problem is when we set the threshold. Because when we regulate the new areas, for instance CI, and we can say oh, there's no problem in terms of liability. We put a strict liability. Every AI producer is liable for all the damages that they create. So all the systems have a person that will pay. A lot of concern about the potential malfunctioning or problem created by AI systems is solved because there are always some that pay. But first, if you adopt an extensive strict liability, the impact is that many investors prefer not investing in a sector in which they risk to be liable and risk desire if technology is new. Because it's less known in this side effect and there are a lot of aspects that should be fixed. So extending too much strict liability can have a sort of chilling effect on investing in the sector. On the other hand, if you rely only on the fault liability, there is that technology that that move. Potentially create a server risk. Of course, at the end of the day, there is no any person that is liable. So increase the concern of AI consumer about the user, about the citizen, against this technology that also this is not good because if people don't like our concern, they don't want to use it. So there is the risk to make a few reactive implementation and stop or slow the implementation of this technology. For this reason, we have to find the right balance between the strict and the fault liability. And what is done, for instance, now with a new proposal on the directive on AI liability, that adopt some rules in terms of strict liability for AI producer, but fix also some derogation to this liability. For instance, if you are compliant with some standards, the compliance of the standards is enough to say that you are not liable, although the damage is created. So is an example of balance. You are strictly liable, so without fault, but compliance with standard exam for liability. It means that you have an exit strategy focusing on the standard implementation that reduce your potential extensive liability. Other solution that can be also implemented are about the participation we can say in the game of other actors, for instance, insurance. In the sector of drones, not military drones, but as bold drones for, I guess, a personal use. In several countries, there is a mandatory insurance for drones because they are cheaper with 200 Euro you can buy a drone, but flying out when they can't fall down, of course, can create damage, also killing person. And you are not necessarily enough money to cover this kind of cost. So like in the cars, you need to have a mandatory insurance so create an entity that can pay this kind of damage. The insurance system is another way to address the problem, maintaining the fault liability, but shifting the cost towards a company that on a large scale can mitigate the impact on the individual costs. What kind of problem can personal drones create, for example, one can fly their drone and see people's house? This is what you're talking about? No. There is also the problem of privacy and watching people, but the typical problem in which we have this liability is when the drone is flying, that for malfunctioning or managing, et cetera, falling down from several meters and landing on the head of someone, open and kill the person, or open the car and destroy the car. And so this is the kind of concern. So the drones, it depends by the dimension, it depends by the weight, et cetera, but under certain circumstances, can create damages to people and to goods. And so for this reason, some countries are required, specific categories of drones, blah, blah, blah, some mandatory insurance. Of course, if it is a small, very tiny drone, not able to fly twice, et cetera, there are exceptions. But if it's a big drone with a couple of kilos of weight and fall down from several meters, the problem exists. Okay, this is the problem. Okay, so insurance is a solution. Another solution for the big case is the role of the state. For instance, in nuclear power, in the nuclear power, we have the participation of the state because the cost of the damages created by malfunctioning in a nuclear center can be so big that cannot be addressed by the company that manage the structure. Another point that we have to take into account when we fix the rules in terms of liability is that it's too simplistic to imagine that if you put all on the shoulder, the company will solve any problem because the company then bankrupt. And if they bankrupt, they first pay bank and other partners that have legal protection to end up with a federal agreement, therefore the last they pay the damages people. So when there is a risk that the damage is so big, like in industrial, in the nuclear sector, it is much better to fix a threshold. Imagine that, till that threshold, the company can address and pay with their own money and furtherize, imagine a sort of socialization of the cost through the intervention of the state. Because if you don't, the only solution is that you fire the company and the company no longer pay the last that can ask in terms of priority for the credit that are damaged people. So again, another aspect that in terms of regulation should be taken into account. Okay, yeah, we have some reference if you like on digital society and risk society. This is something that we already mentioned about the design. These are examples of design in families case of the Paris Boulevard that were being, during the period of Napoleon III, decided to destroy all the small streets. And that was a by design approach because the large streets are much more difficult to be blocked in case of riots and it's easier for the soldiers to resist to any protests in the larger streets. Oh, this street bump devices that are other by design approach in order to limit the cost. This is something that we already said. This is all about the by design approach but repeat what we have already discussed about the limitation of the approach and the impact of the by design approach. So I want to move now to another set of slides. That is about data ethics. Data ethics is divided into parts. We start discussing now data ethics, giving some ideas and then we recall this idea of data ethics when we discuss after the protection part about the AI. Because in the other, I mean a huge debate about the regulation. And the first part of the proposal between 2016 to 2021, we had a lot of focus on AI. And sorry, a lot of focus on ethics and on data ethics as a means to address the challenges of AI. So here we give only some general notion about data ethics but then we discuss more in concrete scenario we can say this issue where we address the topic of AI regulation because for now is the only sector in which we have seen an proper debate and extensive debate about data ethics. For the rest of the, maybe a theoretical or legal debate at academic level. But with the AI we have the flourishing of ethics code, ethics guidance, et cetera. So we have a concrete implementation of the idea of data ethics. So for this reason, we discuss AI in the last part of the first part on the legal aspect of this course. We reconsider the ethical dimension. But before starting the next part with my colleague Giuseppe Vacciagore that is very focused on data protection, I want to just to highlight some general notion about data ethics because it's also useful to understand better the distinction between law and ethics that is also reflected in data protection regulation. So if we look at the ethics, of course, this is an image that can recall you the problem of the ethical use of technology. This is a nuclear fallout. We all know that the problem that we either use a nuclear bomb in several parties of the world in the past then, unfortunately something that was considered as from the past is now dramatically present in the debate about the Russian potential use of a nuclear bomb, although more limited but with always a very huge impact on population and on the environment. So why I started with these photos? Because these photos usually represent the typical mindset that's characterized in the beginning of the debate about the ethics of technology because data ethics is a subtopic of the logic of technology. Such as data protection is a subtopic of technology regulation. So we start from the main topic, the main topic is ethics of technology. In the ethics of technology, the attitude was like the attitude that we have now. So we are looking at the fallout. So the fallout is something that is out of view. It is a technology that creates problem and the rise issue. And you discuss about the ethical dimension of this technology. Is ethical or are unethical using nuclear weapons? Which kinds of applications they have a secret? By the way, it's the same discussion that we have right now with AI powered application for workers. Similar debate about the ethical use of AI powered weapons. So why I want to stress this point that we have sort of external approach. Because this was exactly the first approach that was adopted in the ethics of technology. So the first stage of the debate of ethics of technology consider a technology or something that you can see, you can judge if it's good or is bad. So typical debate on atomic bomb, is it admissible or not? Is good or not? As a role of data science for this reason is acceptable or should have no any kind of role because kill people or we never admit in any case the use of this kind of problem. So the technology is like an object, an artifact that you look and you evaluate. This is a typical approach that we have at the beginning. So a stand-up view, technology as autonomous phenomena focus on the impact on society. This was the first approach that we see in the debate of data, of ethics and technology. Then we move to another picture. In this picture what you can see, you can see a bridge. This bridge is a famous bridge, a series of famous bridge, more correctly, that where the most bridge, the bridge created Moses. Moses was the architect that designed the downtown, the large part of New York in, I think, 50s, more or less. And the most bridge are very evaded topic because this bridge are very peculiar elements. They are very low. The car can pass, but the bus cannot pass under the bridge. At the time, the kind of bus that we were talking about. So what was the ethical problem about the Moses bridge? That this bridge was, the position of this bridge create a sort of barrier in order to access to a new area of seaside where there were new beaches. And these beaches are very close to the Bronx, but people from the Bronx were not able to reach them because they cannot, many of them have not a private car, and the buses cannot pass under the bridge. So the bridge was a barrier for the rich people that come from the other neighbors, passing through the eye of the road and arriving at the beach. So for this reason, but this is very long literature on the part, for this reason, some of those consider Moses as an architect driven by a rush of bias in his design because by design, you see the importance of design, limiting the access to the black people, basically, or the poor people to the new beaches that were created. So why I choose this kind of photo? Because this show another approach to the ethics of technology, or more correctly, to show another dimension, another phase of the relationship between ethics and technology. Because it's no longer something that we look at, but it's something that has a sort of circular relationship with the world. So to be more clear, is not the artifact that you look like the new purple, but it's the bridge that you look about at the same time, limit also your circulation. So there is a mutual relationship. The technology have an impact on society, and the society have an impact on technology. The bridge limit the black people to reach the sea, but the bridge was done in this way because there was a rational approach in society. And this rational approach is reinforced by the technology. So in this regard, the technology is no longer something that we look at, so we consider it's good or bad, but we see also another important dimension of technology that is the fact that this interview is connected with our life. The fact that we have some kind of design and technology impact, for instance, if you drive a car, but the change of the car is only on the right. And if the right hand is not your favorite one, of course, this is a problem. But nobody cares because the majority use the right hand. So this is, and as a consequence, the people that use the left hand typically in driving should learn to use the right hand as the main one. And is a change that technology induced in the behavior of these people, that but is also a result of a majority of the approach of the society. So this mutual relationship between society and technology and technology and society open up to a broader view of ethics of technology. Technology not only something that we discuss is good or bad, but it's something that is much more complicated because it's the result of the society and is able to shape the society. So there are two different and mutual relationships. Please. I want to ensure that what you're saying is that the first approach is not fine for everybody, for example, going to a place, is a semester for everybody, but building a bridge can be fine for some people and not for others, right? Not exactly. I want to point out that there are two approaches and these approaches are in the terms of evolution. The first initial approach to ethics of technology was simply look at the technology and consider if technology is good or bad. But we don't realize that it's not technology that exists in a autonomous way. Is not a technology that is good or bad? Are we as society that create a technology that can be good or bad? So it's not the technology that is bad or is good, but that the value that we put in that technology that can be good or bad. So at the end of the day, the problem is not in the technology, but it's in the way which shape the technology. And another important step is that the way which we shape the technology, then we shape as a society. For instance, why a large part of itania, young people is no longer able to write a good text? Because they spend a lot of time texting in short messages. And in short messages, of course the kind of communication is different. And if you repeat the exercise for hours to use short messages in terms of communication, of course you are no longer able to make an extensive test. Or you can impact on your ability to have an extensive test. Or if you consider also what's that for instance, many of you probably record the messages. And this idea to record the messaging is a shift from the traditional writing culture in messaging to the oral culture. It's a change in part of that. It's a change of behavior of course. And this impact on the way in which we live. Consider another application, Google Map. A lot of people move around in a new city using Google Map. For now this has no high impact, but in the long run we can imagine that a lot of information about the geography of the area will be removed because the people no longer look at the name of the street or look at the direction or ask the people but look at the smartphone. Okay, with some silly effects sometimes. We know, but this means that Google is able to reshape the way in which we shape the geography. It's dependent by the service. But there's impact on society because if you have no access to the service, if you have another smartphone, if you have poor people that have no smartphone, you are not able to find the right direction in a space if the space became only smartphone base in terms of direction. So this is an example of the way in which we shape technology. They reshape the society. Technology is not neutral. Technology always invets a certain kind of view, a certain kind of view. For this reason we discussed about data ethics. Because also in digital technology, in the technology based on data, what we put is a specific view of the society. We reflect our mindset. Google, consider that it's great to have your direction in your smartphone. Why? Because they sell this kind of product, of course. Because being recently told that was great to have a checked search engine in order to provide a better interaction. Recall the fact that this interaction is not so good. But what is the impact of society or about a chat GPT approach? It's quite relevant in terms of anti-colon social impact. Because right now, if you're scouting, you have a list of sources. We can discuss about how the sources are outlining if there is a bias or not in the positioning, et cetera. But we have the sources. It means that if you want to understand, you have to select. And if you are well educated, you are also able to select the right sources. So if the top one is not so alternative and the second one is a big newspaper, probably start from the second one and not from the first one. Because behind it is a market oriented position in yours. But if you make a question and the answer is not a longer list of sources, but is a text that give you the answer, combining these sources. Of course, this make it in the sources. How many people will check the sources if they are the answer? Only few will check the basis of this answer. Like when you read a scientific book, if you are not an academic or a good academic, because they are also bad academic, you usually read the text, but you disregard the footnotes. But in the footnotes, there are the argument and the basis that justifies some assumption in the text. If the footnote is wrong, if the counter of the foot is not corresponding to the text, it means that the text is not well grounded in terms of scientific reasoning. But if the chance GPT search engine give you the answer in a very good way and give you the answer about, for instance, Donald Trump and the role of Donald Trump in society. And in doing that, I got a specific interpretation of the role of Donald Trump and give you the sources, but you do not look at the sources. Of course, this change, the power between you and the search engine, because the search engine is no longer a list of sources, but became a sort of oracle in which you ask can the oracle provide the answer? And you trust in the answer. How do people, as the people trust in the answer of Google, when they ask for a street and they go in the wrong direction sometimes, because the Google map in that case was not consistent with the last changes in the municipality, for instance, okay? So that's happened, that according to the map, just by Google, you have to go in the straight along and go in that direction, but the municipality have changed the direction, you have to stop. So, but what about if this is the answer of the search engine that say something that is not correct, you have to check? It's different of search engine, chat GPT power than an encyclopedia, an encyclopedia, sorry. An encyclopedia has behind a scientific work, as a check, as a review. So it's true that provide you an answer, but this answer is tested by scientific experience, by people in the field. A chat GPT search engine has not this kind of background. Simply select content and much content based on some parameters that are set in the machine, but it's not a scientific output, it's not a research output. And this check may change the way which society have access to knowledge and having access as knowledge is core element in democracy, in research, in many aspects of our society. So this just to figure out some real case or potential implication of the technology that we developed also in the field of digital technology. For this reason is important also as a computer scientist when you develop some digital technology, do not consider only the technology aspect or the economic benefits or the legal constraint, but consider also what is the impact of your technology on society. What is in the medium and the long run, the impact of your technology in society. Because your technology can change society, but we have to ask if this change is according to the values that exist in a specific society, or if simply a stop down exercise in which a company or a big company tried to shape the society in the way that is desirable for the company. And we had some case that we discussed. So the point, the crucial point, that is also represented by a theoretical approach that is the technology variation theory, the crucial point is that technology is not neutral. When you design something, you always design with your mindset. We have made example of social platforms and the grass-riders, etc., all those who are the greatest, etc. So the idea is that when you create some kind of technology, directly or indirectly, you reflect with this technology your view. So for this reason we say that technology is not neutral. Self-initiate is a furnace, censorship when you talk about technology in a critical way. So first the value are embedded, second point, technology mediates between humans and the way in which the human society is set. This is the ideal mediation. You see the things through technology. Let's give you an example. If you consider the proverb analysis, why because that's new to the brain? If you consider the check that is done when you are pregnant before the birth of the kids, of course right now with the ecology or other system it's possible to know a lot. What was the effect of society? That people can decide for abortion in some cases. Before it was not possible. Yeah, it was possible abortion because you don't have to have a baby. But the abortion based on malfunctions, based on some specific disease, etc. Before was not considered simply because it was not technically possible to have that information. But now that we have this information is possible to decide in favor of abortion based on medical evaluation we can say. So the technology changed the relationship between mother of the family and the future baby based on something that before was not possible. This is an example of how we see true technologies, the things. And the same is in the digital context. You see the word through the search engine. The search engine give you a list of content according to some criteria that are not the real words. Maybe there is a very interesting article that is published on a very minor journal that is the best one on the topic. But the fact that the journal is not so well known, there is not a lot of clicking, there is not a lot of advertising, etc. This is not at the top of the results. So technology mediates. And the same is when you use smart cities or analytics to analyze society, etc. You always provide a sort of description of the real world that is mediated through technology. When you look at the map of the distribution and everything it is always a mediation, it depends on the parameters, it depends on the variable that you consider, the granularity that you consider, etc. For instance, if you look at the industrial activities and collect all the data through big data analytics and you represent this information at regional level, at national level, at local level, the result may be very different. For instance, you can say, oh, in Piedmont there is a lot of activity in the industrial sector compared with another region like Basilicata. But then if you look at the Piedmont, it's not true that in all the areas of the Piedmont there is a lot of industrial activities. There are some areas in which there is no any industrial activity. So the different level of representation of granularity give you a different kind of map, a different kind of information. And of course, this changed the perception of the society that we are. And second point that is important to allow, and that is the consequence, is that if the values can be embedded in the technology, including digital technology, of course we have to check which value we are embedding in technology. To check what it means, it means that, first of all, we should be more aware about our role as creator of this technology. For instance, I think that I mentioned with you the case of the insurance that discriminated black people during the night. We discussed that in that or not. There was an insurance that decided to put a black box in the cars in the US. And of course there are some parameters in order to reduce the cost of insurance or increase the cost. One of the parameters was if you drive during the night or the early morning, the cost is higher because usually you come back from a party, drink a lot of alcohol, and this is not good for driving. What was the problem? There are also people that drive during the night or early morning because they leave outside the big cities and go to the big cities for work, not exactly after a party, and to clean offices and like that. And by the way, in the US, these activities are usually done by black people or minorities. And so this created discrimination. And why the algorithm did not consider this aspect? Because it was created by May night computer scientists that never had the idea that you were coming in the early morning to have to clean something. But they consider that if you drive in the early morning it's because you come back from a party because in their own experience this is their experience. So of course computer scientists try to mitigate this bias, potential bias, through having more variety, group of design, etc. But it's not important that there is variety because if it's not the Russian bias there can be many other bias that exist. The problem is to be aware that we can unintentionally reflect our mindset in the creation, in the digital context. So for this reason, for instance, it's important to have participatory approach in the design, including the user, including the target. Because the target population can raise their heads and say, oh, I'm a black. I usually do not drive through in the night because I can get just back from a party. So the idea is that when we discuss about bias, larger parts of bias are not necessarily intentional bias. Of course there are intentional bias. There are applications that are biased in favor to the earth or in favor or some political approaches, etc. It's possible. But this is not the main risk. The main risk are the unintentional bias. The bias that are based on your mindset, that you spontaneously reflect, and you cannot detect because they are not able for you, is normal. And this is exactly the process in shaping society, shaping technology, through technology, reflecting values. So if you consider that the black people should not go to the seaside with the white people and stay in their neighbor, of course the bridge is lower. So you reflect your intention in the system. And for this reason, someone said that it was not a racial approach in creating the bridge. Simply, it didn't consider the fact that there are also black people who do not use color but use basis. So for this reason we have an ethical web design, and for this reason it is important a bi-design approach. That's a few seconds about that. We continue in the part after data protection. I think that a key point that I want to highlight with regard to this slide is that the ethical approach makes it possible to understand that not everything that is technically feasible is also ethically acceptable. There are some things that are technically feasible. You can make some analysis, you can use data in a certain way, but it doesn't mean that it is also acceptable according to the value of society. I can use BrainSkin in order to detect if you are a follower or not my classes, but it doesn't mean that BrainSkin is the best for you as a student's community in order to be good students at the Polytech. So this distinction between technical, physical, and societal acceptable, ethical acceptable is a very core element in terms of ethical design. I think we have stopped in this direction. We continue, sorry we have not finished.