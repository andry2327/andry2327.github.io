 You stayed with my colleague Giuseppe Bacciado discussing about the... what? Vibia only or also cybersecurity? No, only GDPR only. And we have to complete a part on ethics, but I was just checking probably, and if now we can continue with the GDPR and then we move to ethics and make the bridge between ethics and AI, there is a strict connection also, that's a very much. Okay? Yes, please. What is going to be the next one? Good problem. That's it. Thank you. George Thompson? No, George Thompson didn't participate in the lightning strike. Really? No, no. No, no, no, no. I have to go to the bathroom. Really? I think... I think it's nothing. Does it have anderer words? Okay, it's number My, I already upload everything at the beginning of the course. So first before continue the discussion about your question, we just to ask you if everything was clear, you have any doubt, question, etc, etc. I see some people skip the classes, consider the first case. So everything was clear, we have any question, doubts about the GDPR, have you become very expert in the field? You think so? I suggest not over trust if you are expert in the GDPR, it's very complicated. Okay, so now assuming that you have a good basic knowledge of the GDPR, let's try to look to the GDPR in some concrete case implementation just to figure out the situation and to make an exercise that are quite consistent which the kind of exercise that we also make during the exam. As you know the exam is divided for the legal part into question, one is more abstract and theoretical and the other one is more focus on a specific case in which it is asked to you to consider the problem and to find some solution in order to properly address the problem. Of course in a manner that is consistent with the basic notion that you received during this course. Okay, so let's start a brief recap about what you have already discussed with my colleague. Of course one of the most important aspects that we have to deal with in terms of GDPR is the management of the entire process with regard to the risk and the related strategy in terms of a privacy by design approach in order to mitigate potential risk and in order to design a solution that are consistent with the key principles that we have in the GDPR daily in article 5, that the minimization, critical specification, etc. So in this sense I briefly recall the fact that in order to assess the potential risk that impact on the design of our product we have to consider three different aspects in terms of risk management. The general risk that are related to the product on service that we have to deal assuming that in any kind of product service there is always some kind of risk because you always process personal data and so you always have to deal with the principle of the GDPR that should be implemented. Then second point, you might realize that there are some significant risks that require specific solutions in terms of addressing them and in terms also in terms of accountability in order to provide for instance in case of inspection, data protection, back assessment, etc. So a more formalized, we can say, stage of this analysis. Second part, formalized risk assessment and management based on data protection and back assessment is something that is not required in any case. Why is it required? You know, why do we have to carry out data protection and back assessment? I think that we are in the last few weeks talking with the chat GPT, doing the classes, absolutely. So, one, you have to carry out the data protection back assessment. I suppose my colleague I have introduced you to the topic of data protection back assessment and one is required to have an data protection back assessment according to article 35 of the GDPR. Everybody? Take article 35 of the GDPR. You are in a very early stage. What is this? It's not so active as it is. It's not so active as it is. Okay. Really, actually. And tell me when you have to carry out this activity. This is... Search and read article 35 of the GDPR. This is the part. In which case according to article 35, we have to carry out... We are not searching for article 35. You need that. So, this is not exactly article 35. So, in which cases? Come on. In which case? You spent five minutes reading it. In case there is a processing of personal data. Personal data? That's the basic because we are in the GDPR. It's good achievement but something more I suppose. I know it says when it produces, when there are legal effects concerning the network person. A systematic monitoring of a publicly accessible area. Suggestion. When you read the text, it's better start from the first line. What is in the first line? You are enjoying? Read the first line. I am not. I am not. You are enjoying? Read the first line. I think that when you have high risk for the right and freedom of personal personal. Personal personal is nice but natural personal is much better. Okay, so the first line is when there is an high risk in terms of impact of individual rights and freedom. In that case, we have to carry out an impact assessment. A formal impact assessment. Then there are the other lines that pointed out your colleague in which in the paragraph three that you read, there are three cases that are cases in which the legislation presumes, in which the legislator presumes that these are cases of high risk. Okay? What are the cases? You are not to sleep during the class. Okay. There are three cases in paragraph three. What are the three cases in paragraph three? What are? What are the three cases in paragraph three? What matters is, what matters is that a governmentled implementation can be adopted in a public context. We must consider the same thing. undecided. And the same thing will be implemented in a public context. What's the next session? You're standing on a large scale of the technical data as systematic monitoring of the organization. Okay, so your free case is environmental free that are about systematic monitoring in open area, systematic quality of the special material sensitive data, etc. So these three cases are not the only cases in which you have to carry out the impact assessment. The cases in which the law considers that if you are in that case, you have to do that. But for the rest, it's up to you to check the level of risk. If you realize that the level of risk is sign, it means that the impact, the individualized freedom is signed. As a consequence, you have to carry out the data protection impact assessment. If you don't, there is a nice sanction. I think it's 4% of the annual turnover. It's not bad. So, the impact assessment is not required for all the cases. It's required only in the case in which there is a minor risk, in which there is a high risk impacting on individual rights and freedom. This is important because you know, I suppose, that there is another case in which you assess the potential risk in the GDPR. Which kind of risk reassess? Here is the impact of individual rights and freedom. But there's another big block in the GDPR. Insecurity. There are articles, I think it was 24, in which there is a specific obligation for controller and processor, according to their task, to adapt the adequate measure in order to mitigate potential risk in terms of security for data processing. Both are risk-based approaches, but what is important to outline that are different kinds of topic area. Security is about the system, is about the infringement of the system, the protection of the data, etc. Impact, according to article 35 on fundamental rights and freedom, is a different kind of area, much more complicated. Why is much more complicated? Why is much more complicated to understand the impact of individual rights and freedom rather than the impact on security? Is it easier to understand the risk for a system in terms of infringement, in terms of illicit access, unauthorized access, etc. Or the impact in terms of the fact that you have designed a platform which makes possible to spam fake news or to have a behavior that can create a situation like defamation or online harassment, any kind of negative impact on individuals in the black? Or is it more difficult? It's not a much more complicated, because also the securities can be a large scale. They have a lot of cases, but... Exactly, the problem is that in terms of security, it's true that there can be new kinds of attacks, etc. But the system is much more predictable, rigid if you want to say it. Because you know the feature of the system, and you know the kinds of tools, instruments that can be used to attack a system in general. Yes, they can impact something new, but more or less, if you know the state of the art, this is the game. Why considering the impact on individual rights, it's much more complicated, because it's very contextual. I create a video surveillance system using five cameras in a small town at the entry of the town. I create a video surveillance system using one hundredth camera in a small town in all the area of the town. I use cameras that are able to track the people. I use cameras that are able to recognize the face of the people. So there are many nuances that can complicate and make it more impactful to the system according to the technology that you use, according to the context. I talk about the town, but what about if it's a neighbor in which there is an higher level of criminal activity, or is a park with kids that are playing? Of course the impact is different. So it's much more complicated than once the situation with regard to article 35, with regard to impact of fundamental rights and freedom. For this reason, we focus more on that, because the impact in terms of security is quite easy. It's a technical issue, basically. You know how to protect the system, you know what are the potential threats, you have to adopt an adequate system in order to react promptly. I think that Giuseppe talked a lot about data breaches, because he liked it. And so you have to adopt some plans in order to guarantee business continuity and prompt reaction, whatever you want. But this is the easy task. And it's a task that does not impact all your product and service. This is the key point. Article 35 impacts on your product and service. Because when you design a product, we have to consider this. Look at the... Look at the most recent case. What is the most recent case? Chagabit. Okay. I can't devote the entire court to Chagabit this year. Okay. Chagabit, ask Chagabit your risk in terms of security. You have to read these papers sometimes. Pass a week. Yes, it is. A few days ago, there was news that the same text, there is vulnerability in the system that may possible to see the research made by other people through Chagabit. And they stopped the access for a while in order to try to patch this situation. This is a typical security issue in terms of unauthorized access to personal data. Can you classify? And of course, this is problematic. But what about the other debate about the impact on Chagabit in the use in society and the risk that is used to spam fake news or the fact that provides bias information or the fact that can reinforce discrimination existing in society, etc. This is much more complicated than the patch in order to isolate, fully isolate the different areas of individual research. So this example, the real case, is exactly about the difference between assessing the security and assessing the impact of fundamental rights. The second one is much more complicated. And for this reason, we spend a bit more, because it's not an exercise that you're going to exercise, it's what you have to do in order to create a system. If you want to create a system and put it on the market, you have to assess this kind of risk. For this reason, Chagabit, there is an increase in interest, we can say, by several authorities in order to monitor what they are doing, because it's clear that there are marketing interests to put in the market and the product, but without adopting a very responsible approach to innovation. So according to the GDPR, when you create something that may have impact on the interests of freedom, you have to mitigate the potential risk. So this is the background. Just to recap, you have to kind of relieve an analysis, a data account, or the issues that you already know, monitoring the flows of data that is created by the application or by the product, considering which kind of other parties can interact with the product, because you can create a very available system, but part of the system is managed by a third-party company that provides some services to you, and if the third-party company is not so good in terms of security or in terms of design and the potential impact, this of course limits the quality of your system. Then we have also to consider some specific aspects, like the localization of the information. You know that there is a specific regulation in the GDPR on data transfer. Can I discuss that a little bit, please? Yeah? So if you have a very great product, but all the data that you collect are stored in China, you have a problem, because it's not European Union, and you have to consider how to send this data in China, keeping the same level of protection that you have in Europe, and in some countries like China, this is challenging, because there is a local government that is a bit interested in looking inside the data silos, and so in this case it's not enough having standard contracted houses, but as suggested by the data protection board, you have to adopt also technical measures, for instance encryption or other forms that protect your data also in case of a mandatory order by the local government. That's something that sometimes happens in some countries. So the preliminary analysis, the general analysis, about the system that you created, the service that you create, and then we have the risk assessment. Risk assessment, general assessment, although there is not an high risk, you always consider the risk. For instance, if you want to create a platform for booking for hotels, you will not ask about a complete profile of your clients, you don't ask them what they prefer, books or something like that, but you have to focus only on the information that is necessary for booking, because this is a minimization principle, the purpose specification principle. This is a regular form of risk metric, because you reduce the quantity of information that you collect, and the potential impact on individuals. This is the first general assessment of your system, in order to check if it is in line with the minimum requirements, in terms of data protection. Then as we have seen, there are cases in which the specific application contains an high risk, and so you have to carry out an impact assessment. Finally, the worst scenario, in which the impact assessment that you carry out is not able to fully mitigate the potential risk, and you have to ask for advice to the data protection authority. A point that we have to add here, and that is also important, because when we discuss about the AI Act, so the future regression AI, we see that the approach in the AI regression is done differently. In the GDPR, the key point is that it is not possible creating systems that entail an high risk for individuals in terms of impact on their rising freedom. So you have to keep the system under the threshold. If the system entail high risk, this is not possible to put in the market. We see there is a minor section, but we discuss after when we discuss about the prior classification. But generally, it is that high risk systems are not possible. We see that in AI it is different. In AI, we assume that there are high risk systems, and some of them are acceptable, regardless of the fact that the risks are high. This is the article 35 that we already commented on, so it is not necessary to go back about that. An important point is that the article 35 is not a close list of high risk cases. You have to assess the level of risk. There is not a list, like we see in the AI Act, there is not a list that provides the categories of potential high risk applications. It is on your shoulder to evaluate. So what is the consequence? The consequence is that I have been provided also some interpretation, for instance, by the protection authority, in order to better figure out what are the potential cases of high risk. In this sense, if we look at the decision on the work in party, we will see that there is a link. In that decision, you find a sort of additional list of cases, in which according to the European Adaptoitional Authorities, it is possible to envisage high risk in the activity that we carry out. For instance, when you use systematic monitoring, when you use data in order to make possible access to some services, including public services, etc., this may impact on the individuals, because they can limit their access to some benefit, to some services to make a contract with them. Or the nature of the data, the nature of the processing operation, such as merging different data sets, etc., may increase the level of risk. What is the data protection impact assessment? The data protection impact assessment is a document. According to the accountability principle, it is a document in which you describe the risk and describe the mitigation measure that you have adopted. It is in line with accountability, because you have to keep this document in case of inspection, that the protection authority might ask you why you design a system a certain way, and how you address the related risk, and this document shows the answer. So the risk, the measure, and also you have to check if the measure that you have implemented has affected in mitigating the potential risk. So it's not something very theoretical, abstract. You have to define the measure, implement the measure, and check if the measure is efficient in order to reduce the risk. It means that you have reassessed the risk after the measure, and demonstrate that the risk is lower than before. This is nothing new. It's the typical approach of a risk management that exists in many fields, starting from an environment risk to security, the industrial center, all the risks are measured this way. And as the system, identification of the risk, adoption of measure, check if the measure are adequate in order to reduce the risk for an assessment. Another point that we have to consider is that when we carry out an impact assessment, of course this is time consuming, and you have to analyze in the case the system, but what happens? Sometimes you have more than one process that may rise high risk according to Article 25. And so the GDPR, model of the logic, suggests that in the case in which you measure several processes that are similar in terms of structure and their potential impact, it's not necessary to carry out a specific impact assessment for each of them, but you can carry out only one impact assessment, a community impact assessment for all of them. And it's true also if you have different kind of controllers for entities. To give an example, imagine that you have different cities that want to adopt the same platform for citizen participation. Of course citizen participation can create some problems in terms of freedom of speech, in terms of income participation, in terms of democratic participation, exercise of democratic rights, etc. So you have to carefully design the platform in order not to discriminate some groups, to marginalize some groups, or to limit the asset to the participatory platform from some categories of the cities and etc. So in doing that, of course, if more than one city use the same platform, it's not necessary that everyone carry out an individual impact assessment. If they design the same, they can carry out only one impact assessment that works for all of that. Or if you want a more basic problem, if there are several municipalities that adopt smart regional system, it's not necessary to have one assessment for each municipality, but they can join and use the same impact assessment. Of course, the condition is that the system that they use should be always the same, and the situation in which the system is dealt with is the same. Because if there are changes in the system, for instance, one municipality uses a smart camera to track and recognize the people and the other. Of course this increases the impact on individual rights. Or if the context is different, one municipality decides to use this camera in some protected areas like hospitals to use this. Of course, it increases the risk because it does the natural of the people that are more. So you can simplify this obligation in terms of the protection impact assessment, combining similar, we can say, applications that rise the same level of concern, intense of data processing, technology impact, and this will reduce, of course, the obligation. Another thing that is possible, although not so frequent but now a bit more, is the idea that the company or the service that provides you the application can already carry out an impact assessment. What it means? It means that they already assess some risk and try to mitigate it. If you have read again about the chat GPT-4, someone has read the chat GPT-4 documents. You are an engineer a bit far from this topic. You know there is a new version that is chat GPT-4 and there was published a paper, or 18, 90 pages, about the potential risk and how they have mitigated the risk in chat GPT-3 through the fourth version. This is exactly the line of the idea that you can create a basic service already assessing some potential risk that this service entails. What it means? Why I use this example? Because chat GPT is a sort of general purpose application. You can use the chat GPT-4 in a system to dialogue with your citizen in order to provide them some advice about public administration procedures, etc. Or you can use it in schools in order to support students in making their researches up. Very different kind of uses. But although there are different kind of uses, there are some problems that are common to all the uses. And then have a negative impact in terms of wrong answer or bias answer, etc. So the mitigation of general level of this kind of concern of course benefits all the kinds of applications. So in this sense, in this technology that is complicated but also more simple technology, you can carry out an impact assessment based on the fact that some feature of your product or service are already known and you know that may have a negative impact on individuals and you can already set some measure in order to mitigate this kind of impact. For instance, if you create a video camera that is able to track the people, you can already put in the camera option in order to deactivate the continuous monitoring. Or to introduce some feature that for instance blur the face of the people, not making possible to retroalize them, etc. So this feature embedded in the system represents the first level of impact assessment and an adoption mitigation measure. So this is also in the GDPR. The GDPR says that those who product, service and product can already carry out an impact assessment about the potential use of this service and product and introduce some mitigation about the risk. Of course, this is done by the manufacturer taking into account the variety of potential uses. Then when you use the camera in your sitting for video surveillance, of course you have to carry out a sort of integration, sort of additional impact assessment that consider the specific context in which you use the camera. So if those that provide the camera give you the option not to track the people, then it's up to you to decide if you want to use the option or not or in which context the camera will activate the tracking activity or not. And this is very contextual because you know that your camera phrase is used in a specific area where there are a lot of criminal activities and so you set the camera based on the specific situation. So the impact assessment carried out at a general level by the producer cannot go into the days. So it's not so granular in terms of risk assessment, but camera assessment and general risk. Then it's up to you when you use the technology in the specific case to go into the days. Chapter GPT is an example. They have better and reduced the risk that the AI reacts in a crazy way when there are so-called hallucinations, when you make some questions. But of course this is not enough. If you use this AI to provide, for instance, advice to the citizen, you have to consider that the level of risk is higher if, for instance, provide legal advice because the people can trust in the system and decide to make a control or not or to make a legal action or not. So it's very impactful on a potential option. Or use the same solution for a more basic services like provide general information about the legal system or provide general information about the tax system or the very one. One case is that a case-specific customized advice that entails a lot of risk in terms of potential hallucination or vice, etc. The other one is a more generic description of some features that we have in the legal system, etc. that have not so risky in terms of consequences. So the same technology applies for different kinds of purposes and different kinds of risks that you have to consider and to assess. Last point, the Publication of the Protection Impact Assessment is not required by the law. This is the result of the lobbying. Typically, old impact assessments like in environmental impact assessment are public-available because there's an interest in order to better understand the risk. But in this case it's not public-available. It's suggested by the protection authority to make a public-available impact assessment. But usually the public don't like to disclose a lot of information. ChatGPD again is an example. They don't disclose information about the algorithm. They don't disclose information about the training data set, etc. So it's not mandatory the publication transparency about the impact assessment, although suggested by the protection authority. As well as not so strict the regulation in asking for the participation of the stakeholder in the assessment. This is another point that is very important to better understand the impact of some technology to have a dialogue with the people that are potentially affected. We see some cases. Without this dialogue, the risk is that all these problems of the assessment is the result of the thinking among a small team of developers. Imagine what is the world outside of the potential risk, but without having a specific feedback from the real world that can be affected by technology. So sometimes misunderstanding or misinterpreting the situation under your words. Of course, in doing this exercise, we have to assess the risk and as a consequence design the technology in order to mitigate this risk. Since the early stage. So the risk assessment is not the last stage. It's not something that you do at the end of the process, but it's something that since the beginning, drives the way in which you design the product and the service. This is an important point. It's not a final check in terms of legal conformity, but it's a criteria in order to design. It's like for a car in which you, since the beginning, consider the potential impact in terms of environment impact. It's not the last stage. It's part of the entire process. And here is the saying, well, why don't you share with us your opinion? So we better understand your opinion about impact assessment. Yeah. Okay, so keep up on the class. If you like, if you don't, it's a nice day outside. You can enjoy outside. So the impact assessment is part of the design phases. It's important. Not the last stage, but since the beginning, you have to consider, oh, I am processing personal data. How can I manage this issue? I can minimize this issue. It's useless if it's the exercise of the last day before going to the market. Okay, let's start to work. Now it's up to you. You have seen that we have discussed the topic. We have briefly recab the key points. Now we are ready to address the problem. Imagine the situation of a smart factory. You know what is a smart factory? Or industry 4.0, 5.0, 6.0, whatever you want, 0.0. Okay, it's an environment that is characterized by the using of data-driven application and interaction between humans and machine to information. If you have the slides, please make the exercise. Don't go on in the slide because this is the answer to your question. The exercise is something that is useful for you because it's the same exercise that you make when you have to pass the exam because there's a case and you have to apply the knowledge that you have in order to solve the case. So this is the case. Imagine that you have an exam and the case is the case of an ethical scale. This is the ethical scale. An ethical scale is a basic robotic tool that is applied to the body of a person in order to support the person in some activities, reducing the stress of the body and empowering if you want the person in some activities. The escalator can be also used in order to compensate some disabilities of the person in order to have the person that have disabilities in order to perform the ordinary task. In order to work well the escalator should fit with the body. So imagine that you have to design an escalator for an industry and these are the goals. How do you design the escalator? How do you design the escalator? How do you design the escalator? How do you design the escalator? How do you design the escalator that should fit with the body of the people that wear this escalator? It's unwarrable. So... You measure your employees. I measure my employees. Okay. How I measure my employees? Any idea how to measure your employees? I can hide the way. I can hide the way. Okay. Which technology you use to measure your employees? So? In which way? I did but not. I did but not. I mean like advanced equipment. There's no label for which language. Advanced. Advanced button in which sense? Measurement. How do you get this advanced measure? I can hide the way. How you can measure the body of your employees? Yeah. Several solutions. What solution you prefer? Ask the employees. Ask the employees. Ask the employees. Yeah, yeah. The voluntary demand is another topic. What is the means that you use? What means you use to take a measure? Measurement. Measure? I know it's called a measuring tape. Okay. So the traditional question measure. Okay. Like when you want to make some sweets. Okay. Any other ideas? Photograph. Okay. Other ideas please. There must be a miracle. The uniform is not so fitting. It's by size. But the asus schedule should fit to the specific part of the body. For instance, if you look at asus schedule. It fits with the legs and some parts of the body. As it differs from the size. You need the information about the specific points. The size is general. The size is general measure on the body. That's the size. So why don't your colleague suggest a traditional measure? Other solution? A former asking the employees to fill the form with their information. Not so good in terms of answering sometimes. You can't make ranges. Okay. So the shape of the body. People may have the same level in terms of how tall they are. Both different shapes. Please. When you want to do the dental records. There is advice that some like. How many milliseconds the light comes back to the device. There is a software that can model your seat. So you can build a device for modeling your body. Using the light. Yeah. The device that measures how many milliseconds. That's a bit complicated. Yes. That's a future one. Okay. Imagine that a company use that. Some people can be innovative but don't so innovative. It's really kind of like the X-Box. You want the scanner? What is the scanner? It's a 3D scanner. 3D scanner. Okay. So we have a range of options. Take some measurements. Using size of very broad range. Or body scan that is very precise. At the end. The body scan is very precise. What option you prefer? The 3D scanner. You prefer 3D? Yes. Why? Because it's very, very precise. Very precise. Okay. You prefer ranges. Why? Because I cannot hide it. So I have to give as many points as... You are not from data protection. How does it show? It makes me... So the real case. Because this is a project. Founded by Komal. You know Komal is producer of robot. And a brilliant idea of the engineers in Komal was to use... The robots. The robots. Of course, they are engineers. So they prefer body scan. Because it's very precise. And it's true that it's very precise. But what is the problem with body scan? If you use a body scan. What you are doing? You can identify the person. Yeah, start by step. If you use a body scan. Personal data. Which kind of data? Biometric data? I don't see data. Special categories. Also special categories. Some cases, of course. So you collect personal data. Because the body scan is the image of the body. So it's about the person. This is information related to the person. So it's a personal data. Second, this information about the person. In some cases, it can also reveal as information, of course. Third, this information can be a quasi-bio-metric data. Technically, biometric data, according to the GDPR, are the data that are generated by technology through a process. And so this is the case. This is a process for the purpose of identification. Here the purpose is not identification. The difference is when you use a system to check the identity, like fingers scan in order to enter a specific area, and scan in the body to create an esoskeleton. And scan your body not to identify you, but to create an esoskeleton. So in terms of GDPR, this is not exactly a biometric data, technically. But of course, in the category of personal data, it's quite fine as quasi-bio-metric, because it's very close to biometric. And so it gives a risk, desire, because although it's not used for identification, it's true that the dead image can be refers only to one person. The person is not able to change so easily the image created. This is the key point of all the biometric systems. Are much more invasive from a data protection perspective, because you cannot easily change your fingerprints or other parts of the body. Of course, it's possible under certain conditions, but not so nice. Okay? So, the body scan that was the option by the company, of course, from a data protection perspective, it's not so good, because it's made possible to create a very fitting esoskeleton. But this is exactly the exercise that you have to carry out according to Article 35, the balancing test. We have to consider the efficiency of your project, the interest in the best product, and the impact on fundamental individual rights and freedom. Of course, if I look only from the technology perspective in terms of efficiency, the body scan is the best option, because it's made possible to have the best product most fitting the other solution. But as I have to consider also the other aspect, the impact on individual rights, the body scan is quite impactful, because I scan the image of the body of the person, and I can use this image in the future to recognize them, to monitor them, that's it. And the people cannot easily escape from this equation. It's not like a password that you can't change a password, it's totally a password. So, in this option, it's a typical exercise of the Article 35. Balancing the different technologies that are available from the perspective of the impact on individual rights. Many times, from an engineer or technical perspective, or from an economic perspective, some solutions are much more effective, like the body scan. But this solution that are effective should be tested against the impact that they have on individual rights. If the impact is high, is significant, you have to check if there are other options that have less impact. And this is what's suggested by some of your colleagues, the idea to take measures in an old-fashioned manner, if you want to, is much better because reduce the impact. For instance, you can measure people that work in that area, you can define some ranges, and create an azoskeleton that can be extensible, let's say, the way, in order to fit for different ranges. So, keeping in terms of safety and security at quite good high level, because it can fit with the body, but not tied or specifically for the only one person, and collecting very detailed information about this person. The second solution, in terms of data protection, is much better, and at the end, achieve the same result, to have a solution that fits with the body. So this is a typical exercise. The body scan was good, but was impactful. Creating azoskeleton based on a range of measures that can be adapted to this specific situation is much better. It's just invasive, because you take the measure, you can also take the measure of your employee just to define the range, but taking the measure is an anonymous data, typically, because you don't take the name of the people, or if you want to take the name in case the people don't get it, to be measured is something that then you can delete, so at least it can be said on randomized data for a while. But the system is based basically on an anonymous data, and reached the same result. But now we complicate the case. What about if I have to create an azoskeleton for a person with disabilities, a person that has a specific problem in one of his or her legs, and need this azoskeleton to compensate this problem? Is this case different or is it the same? Why is it different? Because it is. It is, okay? But I also answered the other one, needs. What is the difference? Because all needs in order to address the task. But what is the peculiarity of this case? It's a unique azoskeleton because it has a certain problem, that is especially for the people of the day. Yeah, but it's not about the fact that it needs the azoskeleton, because also that one needs the azoskeleton. But... Exactly. The need is not about the azoskeleton, but it's about a title of the azoskeleton. An azoskeleton that is built specifically on the person. This is the difference. Because if you have to compensate some specific limisation, that affects the body of a person, of course this azoskeleton should be designed on the specific body of the person. A universal azoskeleton cannot work well in this case. So in this case, you can't use the body scan or not. It can depend on the disabilities, but we can say that if the level of fitting is required, you can use the body scan. But how do you use the body scan? Because it's a process. You have to consider each step and measure the impact of each step. We say, okay, in this case, the body scan can be okay, because you have to fit perfectly in order to compensate the specific disabilities. Because it's a problem that an arm cannot move in a certain way. Of course, the azoskeleton should fit perfectly. But how do you scan the body of the person in this case? On the input to the body. Exactly. So again, minimisation. You don't take the entire body scan, but only the body scan as far as it's necessary to design the product. The arm, the leg, whatever you need. Good. So, same problem, general problem, but differentionaries. One without body scan, the other with body scan. And in this case, although there's an impact that is higher on personal data, because of the body scan, it's possible because there is the balance of interest. So there's another interest that is health, that is security and safety, that in this case, justifies more invasive impact. Because in order to provide an higher level of safety for this person, it's necessary to have much more information, according to the specific situation of the person. So, all the rights should be balanced in this exercise. In the first case, the impact will rise more than the protection, where you can minimize. In the second case, there is another issue, that is the specific health condition. And this specific health condition can justify some restriction to the health protection, in order to benefit in terms of health condition. But the game goes on. Okay, body scan, the person. And create a digital scan. What about the image that you created through the body scan, after you have created a digital scan? How do you manage this information? You can't delete it. You all agree that we can't delete after the creation of the ESO Scatter? You don't agree? Why? Maybe I need to, maybe it broke or whatever, so I still need information to repair it in some way. ESO Scatter? Or the person? No, the ESO Scatter. I know, if it's broken, it's not a problem, because you have the shape and the measure of the ESO Scatter. You don't need the shape of the body. Like when a car is broken, you don't need the dimension of the box. I need the project. You have the product, so you have the ESO Scatter. If something is broken, you know the measure of each part of the scatter, you can easily replace some part with another. But there is a possible argument in order to keep the data. The first general rule is delete the data. According to minimization, it's a very high sensitive data. But one, we can imagine that we can keep the data. We can transfer this data to the quote. You can't encrypt the data, but you still remain data-valued. But in which case, you can keep the data, in a legitimate way. There might be some situation. What is the strength of the developers? There might be cases in which the disability can't change over time. What will be the consequence? You have to make other scans periodically. And also the procedure to make scans is quite invasive. So it's much better in that case to keep the first scan unchanged, according to what is changed over time. So, general rules, nobody scans. More limited area, yes, but it's done for specific disease in order to compensate. But destroying the information after this scatter is created. Subsector rules, keep the information. If the person can change in disability or health condition over time, this will be quite an update of this scatter. Three different kinds of processing in the same situation. This is a typical exercise that you have to carry out when you consider the impact. Consider the impact, and consider a different situation. Balance is the different competing interest in order to design what is the most appropriate by design approach. Now it's clear what is privacy by design. Privacy by design is that. That the design of the scatter is shaped in a manner to reduce the impact in the use of data, the impact on the individuals, according to the different situation. So there is not necessarily one solution fit so in our analysis because we have to consider a different situation. Some applications may have different situations. We put a video camera in a square. The video camera can be used to monitor how many people are in the square just to know the traffic, you can say. It can be used to monitor crime, so people that are fighting the street or can be used to monitor the cars that are passing through. Different features in the video camera can be used in order to properly address these three different categories. Not to be invasive for the situation that are not in these categories. For instance, the people that pass through the city and are working in the square and don't want to be monitored. So this is the enterprise that is necessary from the legal and technical side. And in computer science this is very important. So to understand that you have to consider a different option and the different options, the selection is not driven only by the technical needs but also in terms of potential impacts on the individuals. So a very good option for a technical perspective cannot be a very good option in terms of impact on the data protection. And you have to combine both and find the right solution. And our risk is the same as the biometric definition of biometric. If you look biometric that are different from specific things, you have process the physical, psychological, behavioural, characteristic, or natural person which allow or confirm the unique identification. This is the definition of biometric. For this reason it is a quasi-biometric because the purpose is not to identify. And you provide a qualification according to what is the clear purpose. Of course, it can be also used to identify, but this was not the purpose of the application. Some definitions from the opinions so that the better to find the biometric and the role of the body to be machine-readable, you can say. And some information about health data. Any kind of information to physical or mental health to reveal information about health standards. This was the project with the different partners. And this was the solution. We didn't mention the third model that was not implemented in the project. That was the productive as a scatter. So I am able to predict your movements and to anticipate and help you in the movement. What about this third category? Not necessarily an efficient. Bermaric's perspective. In this lower or higher risk? Compared to the other one. An higher risk because the prediction can be wrong. I can break your leg or break your arm. So predicting models are possible. They are working on that. But should be very careful management. Because it's not a problem of data protection only by separate safety. So you have also seen in these analysis how you have to combine the different points. So which data you collected. For which purpose. Why by design approach you have to adopt. How do you manage that retention. So the fact that you keep information like the information about the body and sit down. This was exactly the idea that they had at the beginning. You have the information that we have. The first model is based on anonymous data. The exception, etc. Last point that we have to address is the fact that when you create the biometric information. There is a critical point about the control of this information. I give an example. Let's consider another scenario. You are a company and you want to use biometric tools. In order to identify the people when they enter in the room or in all the areas of the company. In order to avoid that someone enters in the wrong office or something etc. Is this possible using this extensive biometric approach? Yes or no? Pardon? I want to use biometric in order to identify the people when they enter in the office. When they enter in public spaces. For instance you want to go to the canteen. You have not to show your card but there is a face recognition that admits you immediately. Or when you enter in your office you don't need the key but you touch and recognize your fingerprints and open the door. Or a vocal command or whatever. So based all the access in all the areas with these devices. Is it possible or not? Any idea? It depends on the company. What is the sense and the security? Why depends on the company? As you mentioned taking the canteen as an option compared to the room. You can't take these transportation tools as high-discount offices. So we can actually implement this compared to the relief of the police. We cannot use such things because such things have to be encrypted. There are a lot of problems that you can't solve. So you don't work for the canteen but you work for some areas. Public spaces for instance should not have such an offer compared to the rest of the community. Ok this is exactly the point. So we cannot use this approach in a general way. But to the fact that it increases the risk and the impact you can justify the impact. Considering what other competing industry should be protected. For instance one reason can be the fact that some areas in this are risk for the safety of the person. For instance consider a chemical plant in which there are some areas with high chemical risk. And only people that are properly trained and expert can access this area. So what are the risks mainly in the emergency situation? Using a system that concerns a quick identification like some parts of the body scan we can say. Fingerprint, face, or the irid, whatever you want. It's useful and also limiting the risk for people that are not authorized to go to the hospital. And this is a justification because the impact on the protection is compensated by the safety reasons. Again, balance of interest. But for instance in other areas like canteen or public space or also your office can be disproportionate. So it's possible but why use a biometric when you can use a card or a key or many other devices that are not so interesting. But in this case, in the case in which you use biometric, there's a second step. Imagine that you can use biometric in some areas. Which kind of biometric information you collect in order to identify the person. For instance, small possible months, so better fingerprints or better face. And why is better than face? In the simplest example, it's identical prints. Okay, in terms of identity, it's better but also in terms of brightness it will be better because reduced the number of months for the parts of the body. Because for instance, if I collect the fingerprints, the fingerprints can be collected to understand, we can say. Using a touch system, you have to put the fingerprints. While if you use a face, the face can be recognized in the crowd. So if I collect your face and you authentify your face, the same image can be also used to recognize you in the crowd. With a fingerprint, it's impossible to recognize you in the crowd. Because the only solution is to take a picture of your fingerprints and high definition picture. And then recreate the fingerprints. They did something like that for a lot of the past. But it's very difficult. So it's important to consider the different parts of the body in terms of... Ability to be collected in open spaces or re-using other contexts. Are much more sensitive, we can say, than other parts of the body. You can easily protect your fingerprints than your face, we can say. And then the fingerprints can be reduced to only one finger rather than more than one. So the fingerprint is one solution. So, limit the information that we collect. The second point is, how works a system based on fingerprint identification? Do you know? How it works? Technically. Let's see. How is it possible to identify me using my fingerprint? We need a database in which there is all fingerprints. What do you mean, all fingerprints? All of them. What do you mean? All of them. Yeah, yeah, but it's the promise of the fingerprints. What kind of information you collect in the database? The picture. The lens. The lens? So all the lines of the fingerprints? It's unique. Of course, it's unique, actually. But... So what do you take? The image of the fingerprints. That's a computer science you have to study people. On this technology. Exactly. Think about the face recognition. You take the picture? No, you take the points. You take the points that according to the different kind of the body, can be more or less, but you don't need the entire image. You need enough number of points that make unique identification. Okay? So you typically collect what is called a template. A template means this kind of information about some points and the distance among the points that is stored. So it's not a serious image of the fingerprints, but it's mathematical information, typically the number of points and the distance between the points and their distribution. So it's a line of mathematical information. This information is collected by the system. And you need a sensor. What do the sensor? Scan and... Scan, extract the points, and compare the points with the points that are in the templates. Okay? This is the system. How you design this system in order to identify your employee in the industry? Where you put this information? The templates. In the company servers. All you want fingerprinted in the company servers? Is this the most surprise-oriented option? No. Of course it's not so surprise-oriented because it means that the company collects all the template of the employees that use this kind of identification. So it has a power that will control. What is an alternative more surprise-oriented than that? We're not only using devices where you can... In what sense? In which device? In my office. I could only use my information there. Where? And the device is the door. Because you put the fingerprint on the door. And the scanner. And the scanner is connected. The scanner is a scanner. You need a repository for the information. No, the scanner can also not store the data in memory. It can simply compare not to the data in the data. The problem is where you put the archive. Where you put the database. You are close to the solution. But the last stage about the device was the missed one. Where you put the information if you don't want to create a centralized database in the end of the company? This means... This means... Okay, this is all about the country. How you do that? Where you put? Because we are... It's nice distributed, centralized, but how? For example, in the Amazon system. Cloud. Internet is not a solution. Because it's distributed under the control of the company. It's only the distribution of the data. But it's not the distribution of the control. It's the remaining data. All those data used the cloud. But this is distributed, it's okay. And you have to combine the distributed data. Say it by your phone. My personal device. Oh, your personal device. What device, typically? Not on your phone. Something much better than your phone. On your card. You put the card, you put the finger. In the card there is the template. The system compares the image extracted from the finger. With the template that is in the card. If they match, you keep out the card, you keep out the finger. No centralized system. And the template with the biometric information in the end of the data subject. So, most safety place. Protected by encryption if you want. In case someone can steal your card. Or you lost your card somewhere, etc. So, this is an example. But you look how, thinking about the design, you reach a different system. The system that you think at the beginning was a biometric system. Very extensive in that collection. And very centralized. The final system is with a few biometric data in the end of the data subject. This is the exercise. Typically we start to hold with the technician and the engineers, the worst scenario. But then with the exercise. But because the worst scenario is the most efficient. Typical. Of course, a centralized database for the fingerprint is easier to create. It's much more complicated when you have a decentralized card and the people lost the card, you have to replace. Of course. But this is an attitude trade-off that we have to focus on. We have to protect privacy. This creates a cost of course in terms of efficiency. But it justifies because in Europe and many other countries we are convinced that the protection in the internet is much more important than efficiency or other aspects. Okay? So, decentralized means that. Okay. Second case. And then we make a break. No, I'm not sure. I don't know how to find this. The second case is self-adapting workstation. I think I know how to find this. What means self-adapting workstation? Workstation that adapts to your measure. Your tab, your cocktail can move. But that also to your body physical parameters. You are tired today or at the end of the shift you are slower than at the beginning, etc. And the system follow you. That's much better in terms of working condition, etc. To do that, what you need? How you can adapt to the single user of the workstation. How is possible? What you need technically? To adapt the workstation to the person that uses it. Sensor. Sensor. A lot of sensors, of course. You need a lot of sensors in order to detect the bodies, to detect the movement of the bodies and the condition, if it's tired or not, etc. You need sensors. Sensors that collect information. Is this information personal data? Why, yes. But... Pardon? Yeah, but... We are collecting the body temperature. The body temperature is personal data? No, it's personal data. Because you put it in the... It may be also special categories. But before, to be in special categories, it is personal data. Is it personal data or not? No, it's university data. It's something university data. Okay, look at the context. There is an employee that works in a workstation. There is a sensor that collects information about the temperature. Is it personal data or not? Not necessarily always the same, but... You are on the right path. The problem is that personal data is... Any information referred to are identified or identifyable. So it's true that they have a number about the temperature. But I am in a factory. And in many factories, you cannot decide to work whatever you like. But you have a shift and you have a position. So if I know that in the position of 15, the temperature is 37.5, I have somewhere registered that says who is in position 15 at 5 p.m. today. Because usually in a company, the people take the position according to some organization. So if there is another person in the company, they have to work in a factory. And they have to work in a factory. So they have to take the position according to some organization. So if there is an organization that may be possible to match this information between the sensors and the person that is carrying out the activity, of course this is in the best solution, say, normalized data. If you can keep separate information about the identity and information about the sensor information. If the working environment is completely different, which is a lot of people, everyone can stay everywhere, of course this is closer to the idea that there are anonymous data. But at the same time, you know, personalized workstation is much better to have said normalized data than full anonymous data. Because if you have to tailor with a specific person, it's much better not to change every three minutes the person that is using the workstation. So in terms of efficiency, of course this needs to more personalized work. So if I collect this data, and we assume that at least there are customized data, so our personalized data, what kind of measure I have to adopt in order to mitigate potential impact in terms of data protection? What is the key point? The sensor collect information about the user of the workstation. The problem from data management, what is? What is the problem? Okay, while you are collecting the data, and this is to address because you can collect only the data that are necessary for the interaction with the workstation, no more than for the workstation. Second point, what data, and the second, typically is? Stories. We have to save the stories. Exactly, how long I can keep the data? There are always these two elements. Which data I collect are enough or not, are for the purpose of not, and how long I can keep the data? Then there's also the third option, can I share the data with another person, but this environment is not working. Okay, so data storage is an issue. How long can I keep this data? It means at the end is working life? So if they stay 30 years, I have information for 30 years about the person that was in the workstation. Okay, periodic. Other ideas? Why at the end of the shift are not for 30 years? Because the body can work in different workstations every day. So you need to collect again for each workstation, and then tell them to wait. But I can also maintain a previous one. But you can also maintain the same workstation every day. Yeah, but now, the problem is to understand the exercise. The exercise from data protection perspective is, the storage should be justified for the purpose. How you justify the fact that you keep the data for the entire working life of the employee inside the company? If this is the option that's not. You have to demonstrate that you need this data for 30 years to keep the data. After 20 years to know what 20 years before was doing in terms of sensor, the person in the workstation. Do you really need this information? To know that Mr. Rossi, the third of December or 2005 was in the workstation, and the temperature, the body temperature was 35.5. After 20 years, do you need this information? Probably not. So this is the question to understand if you need or not this information. How long do you need this information? At the end of the shift, because during the use of the workstation, some monitoring is necessary to interact with the workstation. But why do you stop using the workstation? It's no longer useful. In this case, you can imagine other shenagra, we see another shenagra later. That's it, so we have to consider other options in this workstation. For example, the sensor collects information about the stress and temperature, etc. This collection is continuous or is one-shot or periodic. Because it's changed. Periodic? It depends on the nature of the purpose for which we collect information. For instance, the temperature can be interesting at the beginning of the shift in order to check the condition. We can say it's an observation, but it's not necessary to monitor the temperature after one hour, but we assume it's the same. Or it can be necessary if it works in an area where there is high temperature, and we have to check the temperature of the body in order to allow the person if the high temperature can affect their body. So, all everything is always contextual. There is not one solution for everything. In some cases, we can justify a continuous monitoring in other notes. And again, in the case of people with some specific needs. Imagine a person that uses this workstation and has some earth diseases. It's necessary to monitor some parameters in order to make possible to work without stressing the area. In that case, a continuous monitoring can be justified. And also, a fully-identified monitoring. So, I need to know the person, because I need to know that person, and one of that person, exactly, during the turn shift. So, again, the exercise should be very, very contextual. Actually, based on GDPR or law, can we monitor or collect these features, for example, the students or these features? Yeah, in the times of GDPR, it's possible where it's justifying terms of violence of interest. In this case, you can say this workstation is better for the user, reduce the stress, etc. And so, if the monitoring is justified for this kind of interaction, it's okay. The other issue that we don't discuss is the issue of labor load. Labor load are some specific provisions in terms of data protection in many countries that are against the monitoring of the employees. And requests of specific authorization, usually from the Federal Union, where you want to implement the system ideas for you. Not to transfer the company in a sort of big broader form than people that need it. And it's also interesting, because this is a case in which the rights, except as such, is exercised not at an individual level, but collectively. The Trade Union agrees with the monitoring system. On behalf of all the employees, but it's not an individual decision. So, it's one of the few cases in which we are collecting dimension of the protection, in the case of individual protection. Okay? Okay, let's make a break.